{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Techniques (CSE6024) Cycle Sheet-3\n",
    "\n",
    "<h2>ANKITA SINHA (20MCI0003)</h2>\n",
    "\n",
    "\n",
    "<h3> Team Members: 20MCI0014, and 20MCI0010 </h3>\n",
    "\n",
    "<p><b>Libraries used:</b> numpy, pandas, matplotlib.pyplot, math, random, and itertools.</p>\n",
    "<p><b> Datasets used:</b> transations.txt, satgpa</p>\n",
    "<h2>Association rule mining-Apriori Program</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chocolate candy coke mango peanut\n",
      "\n",
      "pen luggage comforter bag cap detergent towel \n",
      "\n",
      "chocolate pen candy luggage \n",
      "\n",
      "chococate candy coke \n",
      "\n",
      "pen luggage comforter bag\n",
      "\n",
      "chocolate candy coke mango\n",
      "\n",
      "pen luggage comforter bag cap \n",
      "\n",
      "pen luggage comforter bag cap detergent \n",
      "\n",
      "pen luggage comforter\n",
      "\n",
      "candy mango luggage bag\n",
      "\n",
      "coke peanut detergent towel\n",
      "\n",
      "mango pen comforter cap\n",
      "\n",
      "bag cap towel peanut\n",
      "\n",
      "pen luggage comforter chocolate candy\n",
      "\n",
      "pen luggage comforter mango peanut\n",
      "\n",
      "comforter bag cap candy coke mango\n",
      "\n",
      "peanut candy cap towel\n",
      "\n",
      "pen peanut comforter chocolate \n",
      "\n",
      "pen peanut comforter chocolate cap candy\n",
      "\n",
      "chocolate peanut mango luggage bag towel detergent \n",
      "\n"
     ]
    }
   ],
   "source": [
    "data = open(\"transations.txt\")\n",
    "\n",
    "with data as d:\n",
    "    for line in d:\n",
    "        print(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please enter support value in %: 50\n",
      "Please enter confidence value in %: 50\n"
     ]
    }
   ],
   "source": [
    "support = int(input(\"Please enter support value in %: \"))\n",
    "confidence = int(input(\"Please enter confidence value in %: \"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['chocolate', 'candy', 'coke', 'mango', 'peanut'], ['pen', 'luggage', 'comforter', 'bag', 'cap', 'detergent', 'towel'], ['chocolate', 'pen', 'candy', 'luggage'], ['chococate', 'candy', 'coke'], ['pen', 'luggage', 'comforter', 'bag'], ['chocolate', 'candy', 'coke', 'mango'], ['pen', 'luggage', 'comforter', 'bag', 'cap'], ['pen', 'luggage', 'comforter', 'bag', 'cap', 'detergent'], ['pen', 'luggage', 'comforter'], ['candy', 'mango', 'luggage', 'bag'], ['coke', 'peanut', 'detergent', 'towel'], ['mango', 'pen', 'comforter', 'cap'], ['bag', 'cap', 'towel', 'peanut'], ['pen', 'luggage', 'comforter', 'chocolate', 'candy'], ['pen', 'luggage', 'comforter', 'mango', 'peanut'], ['comforter', 'bag', 'cap', 'candy', 'coke', 'mango'], ['peanut', 'candy', 'cap', 'towel'], ['pen', 'peanut', 'comforter', 'chocolate'], ['pen', 'peanut', 'comforter', 'chocolate', 'cap', 'candy'], ['chocolate', 'peanut', 'mango', 'luggage', 'bag', 'towel', 'detergent']]\n"
     ]
    }
   ],
   "source": [
    "C1 = {}\n",
    "transactions = 0\n",
    "D = []\n",
    "T = []\n",
    "with open(\"transations.txt\", \"r\") as f:\n",
    "    for line in f:\n",
    "        T = []\n",
    "        transactions += 1\n",
    "        for word in line.split():\n",
    "            T.append(word)\n",
    "            if word not in C1.keys():\n",
    "                C1[word] = 1\n",
    "            else:\n",
    "                count = C1[word]\n",
    "                C1[word] = count + 1\n",
    "        D.append(T)\n",
    "print(D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FREQUENT 1-ITEMSET\n",
      "[['pen'], ['luggage'], ['comforter']]\n"
     ]
    }
   ],
   "source": [
    "L1 = []\n",
    "for key in C1:\n",
    "    if (100 * C1[key]/transactions) >= support:\n",
    "        list = []\n",
    "        list.append(key)\n",
    "        L1.append(list)\n",
    "        \n",
    "print(\"FREQUENT 1-ITEMSET\")\n",
    "print(L1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apriori(Lk_1, k):\n",
    "    length = k\n",
    "    Ck = [] \n",
    "    for list1 in Lk_1:\n",
    "        for list2 in Lk_1:\n",
    "            count = 0\n",
    "            c = []\n",
    "            if list1 != list2:\n",
    "                while count < length-1:\n",
    "                    if list1[count] != list2[count]:\n",
    "                        break\n",
    "                    else:\n",
    "                        count += 1\n",
    "                else:\n",
    "                    if list1[length-1] < list2[length-1]:\n",
    "                        for item in list1:\n",
    "                            c.append(item)\n",
    "                        c.append(list2[length-1])\n",
    "                        if not has_infrequent_subset(c, Lk_1, k):\n",
    "                            Ck.append(c) \n",
    "                            c = []\n",
    "    return Ck"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def candidateSet(S,m):\n",
    "    return set(itertools.combinations(S, m))\n",
    "\n",
    "def has_infrequent_subset(c, Lk_1, k):\n",
    "    list = []\n",
    "    list = candidateSet(c,k)\n",
    "    for item in list: \n",
    "        s = []\n",
    "        for l in item:\n",
    "            s.append(l)\n",
    "        s.sort()\n",
    "        if s not in Lk_1:\n",
    "            return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def frequentItemsets():\n",
    "    k = 2\n",
    "    Lk_1 = []\n",
    "    Lk = []\n",
    "    L = []\n",
    "    count = 0\n",
    "    transactions = 0\n",
    "    for item in L1:\n",
    "        Lk_1.append(item)\n",
    "    while Lk_1 != []:\n",
    "        Ck = []\n",
    "        Lk = []\n",
    "        Ck = apriori(Lk_1, k-1)\n",
    "        #print \"CANDIDATE %d-ITEMSET\" % k\n",
    "        #print \"Ck: %s\" % Ck\n",
    "        for c in Ck:\n",
    "            count = 0\n",
    "            transactions = 0\n",
    "            s = set(c)\n",
    "            for T in D:\n",
    "                transactions += 1\n",
    "                t = set(T)\n",
    "                if s.issubset(t) == True:\n",
    "                    count += 1\n",
    "            if (100 * count/transactions) >= support:\n",
    "                c.sort()\n",
    "                Lk.append(c)\n",
    "        Lk_1 = []\n",
    "        print(\"FREQUENT %d-ITEMSET\" % k)\n",
    "        print(Lk)\n",
    "        for l in Lk:\n",
    "            Lk_1.append(l)\n",
    "        k += 1\n",
    "        if Lk != []:\n",
    "            L.append(Lk)\n",
    "    \n",
    "    return L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FREQUENT 2-ITEMSET\n",
      "[['comforter', 'pen']]\n",
      "FREQUENT 3-ITEMSET\n",
      "[]\n",
      "ASSOCIATION RULES:\n",
      "RULES \t \t \t \t   SUPPORT  CONFIDENCE\n",
      "Rule  1 : ['comforter'] --> ['pen']     50     90\n",
      "Rule  2 : ['pen'] --> ['comforter']     50     90\n"
     ]
    }
   ],
   "source": [
    "def associationRuleGen():\n",
    "    s = []\n",
    "    r = []\n",
    "    length = 0\n",
    "    count = 1\n",
    "    inc1 = 0\n",
    "    inc2 = 0\n",
    "    num = 1\n",
    "    m = []\n",
    "    L= frequentItemsets()\n",
    "    print(\"ASSOCIATION RULES:\")\n",
    "    print(\"RULES \\t \\t \\t \\t   SUPPORT  CONFIDENCE\")\n",
    "    for list in L:\n",
    "        for l in list:\n",
    "            length = len(l)\n",
    "            count = 1\n",
    "            while count < length: \n",
    "                s = []\n",
    "                r = candidateSet(l,count)\n",
    "                count += 1\n",
    "                for item in r:\n",
    "                    inc1 = 0\n",
    "                    inc2 = 0\n",
    "                    s = []\n",
    "                    m = []\n",
    "                    for i in item:\n",
    "                        s.append(i)\n",
    "                    for T in D:\n",
    "                        if set(s).issubset(set(T)) == True:\n",
    "                            inc1 += 1\n",
    "                        if set(l).issubset(set(T)) == True:\n",
    "                            inc2 += 1\n",
    "                    if 100*inc2/inc1 >= confidence:\n",
    "                        for index in l:\n",
    "                            if index not in s:\n",
    "                                m.append(index)\n",
    "                        print(\"Rule  %d : %s --> %s     %d     %d\" %(num, s, m, 100*inc2/len(D), 100*inc2/inc1))\n",
    "                        num += 1  \n",
    "\n",
    "associationRuleGen()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>K-Nearest Neighbors (KNN) Program</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Use matplotlib in Jupyter Notebook Outputs\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = [[1590,2.9], [1540,2.7], [1600,2.6], [1590,2.7], [1520,2.5], [1540,2.4], [1560,2.3], [1490,2.3], [1510,2.4],\n",
    "     [1350,3.9], [1360,3.7], [1370,3.8], [1380,3.7], [1410,3.6], [1420,3.9], [1430,3.4], [1450,3.7], [1460,3.2],\n",
    "     [1590,3.9], [1540,3.7], [1600,3.6], [1490,3.7], [1520,3.5], [1540,3.4], [1560,3.3], [1460,3.3], [1510,3.4],\n",
    "     [1340,2.9], [1360,2.4], [1320,2.5], [1380,2.6], [1400,2.1], [1320,2.5], [1310,2.7], [1410,2.1], [1305,2.5],\n",
    "     [1460,2.7], [1500,2.9], [1300,3.5], [1320,3.6], [1400,2.7], [1300,3.1], [1350,3.1], [1360,2.9], [1305,3.9], \n",
    "     [1430,3.0], [1440,2.3], [1440,2.5], [1380,2.1], [1430,2.1], [1400,2.5], [1420,2.3], [1310,2.1], [1350,2.0]]\n",
    "\n",
    "Y = ['accepted','accepted','accepted','accepted','accepted','accepted','accepted','accepted','accepted',\n",
    "     'accepted','accepted','accepted','accepted','accepted','accepted','accepted','accepted','accepted',\n",
    "     'accepted','accepted','accepted','accepted','accepted','accepted','accepted','accepted','accepted',\n",
    "     'rejected','rejected','rejected','rejected','rejected','rejected','rejected','rejected','rejected',\n",
    "     'rejected','rejected','rejected','rejected','rejected','rejected','rejected','rejected','rejected',\n",
    "     'rejected','rejected','rejected','rejected','rejected','rejected','rejected','rejected','rejected']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i in range(len(X)):\n",
    "    if Y[i] == 'accepted':\n",
    "        plt.scatter(X[i][0], X[i][1], s=120, marker='*', linewidths=2, color='green')\n",
    "    else:\n",
    "        plt.scatter(X[i][0], X[i][1], s=120, marker='+', linewidths=2, color='red')\n",
    "        \n",
    "plt.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def most_found(array):\n",
    "    list_of_words = []\n",
    "    for i in range(len(array)):\n",
    "        if array[i] not in list_of_words:\n",
    "            list_of_words.append(array[i])\n",
    "            \n",
    "    most_counted = ''\n",
    "    n_of_most_counted = None\n",
    "    \n",
    "    for i in range(len(list_of_words)):\n",
    "        counted = array.count(list_of_words[i])\n",
    "        if n_of_most_counted == None:\n",
    "            most_counted = list_of_words[i]\n",
    "            n_of_most_counted = counted\n",
    "        elif n_of_most_counted < counted:\n",
    "            most_counted = list_of_words[i]\n",
    "            n_of_most_counted = counted\n",
    "        elif n_of_most_counted == counted:\n",
    "            most_counted = None\n",
    "            \n",
    "    return most_counted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_neighbors(point, data, labels, k=3):\n",
    "    n_of_dimensions = len(point)\n",
    "    \n",
    "    neighbors = []\n",
    "    neighbor_labels = []\n",
    "    \n",
    "    for i in range(0, k):\n",
    "        nearest_neighbor_id = None\n",
    "        smallest_distance = None\n",
    "        \n",
    "        for i in range(0, len(data)):\n",
    "            eucledian_dist = 0\n",
    "            for d in range(0, n_of_dimensions):\n",
    "                dist = abs(point[d] - data[i][d])\n",
    "                eucledian_dist += dist\n",
    "                \n",
    "            eucledian_dist = np.sqrt(eucledian_dist)\n",
    "            \n",
    "            if smallest_distance == None:\n",
    "                smallest_distance = eucledian_dist\n",
    "                nearest_neighbor_id = i\n",
    "            elif smallest_distance > eucledian_dist:\n",
    "                smallest_distance = eucledian_dist\n",
    "                nearest_neighbor_id = i\n",
    "                \n",
    "        neighbors.append(data[nearest_neighbor_id])\n",
    "        neighbor_labels.append(labels[nearest_neighbor_id])\n",
    "        \n",
    "        data.remove(data[nearest_neighbor_id])\n",
    "        labels.remove(labels[nearest_neighbor_id])\n",
    "    return neighbor_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def k_nearest_neighbor(point, data, labels, k=3):\n",
    "    while True:\n",
    "        neighbor_labels = find_neighbors(point, data, labels, k=k)\n",
    "        label = most_found(neighbor_labels)\n",
    "        if label != None:\n",
    "            break\n",
    "        k += 1\n",
    "        if k >= len(data):\n",
    "            break\n",
    "            \n",
    "    return label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'accepted'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "point = [1500, 2.3]\n",
    "k_nearest_neighbor(point, X, Y, k=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Multi Layer Perceptron Program</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import random \n",
    "import math\n",
    "from numpy import dot,exp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Network( model_structure):\n",
    "    global no_of_layers \n",
    "    global model \n",
    "    global W \n",
    "    \n",
    "    np.random.seed(0)     \n",
    "    no_of_layers = len(model_structure)\n",
    "    \n",
    "    model = model_structure\n",
    "    W = [] \n",
    "\n",
    "    c = no_of_layers - 1\n",
    "\n",
    "    for Layer in range(c):\n",
    "        w = 2*np.random.rand(model[Layer] + 1, model[Layer+1]) -1\n",
    "        W.append(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "e=np.exp \n",
    "\n",
    "def tanh(x):\n",
    "    return (1.0 - e(-2*x))/(1.0 + e(-2*x))\n",
    "\n",
    "def dy_dxTanh(x):\n",
    "    return (1 + tanh(x))*(1 - tanh(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MultiLayerPerceptron( a,actual_value,alpha): \n",
    "        y = a\n",
    "        d=len(W)-1\n",
    "        for i in range(d):\n",
    "            weighted_sum = np.dot(y[i], W[i]) \n",
    "            f_of_x = tanh(weighted_sum) \n",
    "            f_of_x = np.concatenate((np.ones(1), np.array(f_of_x)))\n",
    "            y.append(f_of_x)\n",
    "        \n",
    "        weighted_sum = np.dot(y[-1], W[-1]) \n",
    "        f_of_x = tanh(weighted_sum)    \n",
    "        y.append(f_of_x)\n",
    "    \n",
    "        error = actual_value - y[-1]      \n",
    "        change = [error * dy_dxTanh(y[-1])] \n",
    "\n",
    "        for i in range(no_of_layers-2, 0, -1):\n",
    "            error = change[-1].dot(W[i][1:].T) \n",
    "            error = error*dy_dxTanh(y[i][1:])\n",
    "            change.append(error)\n",
    "        change.reverse()\n",
    "        \n",
    "        for i in range(len(W)):\n",
    "            Layer = y[i].reshape(1, model[i]+1)\n",
    "            delta = change[i].reshape(1, model[i+1])\n",
    "            W[i] = W[i]+ alpha*Layer.T.dot(delta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit( data, target_labels, alpha, epochs=100):\n",
    "        ans = np.ones((1, data.shape[0]))\n",
    "        Zita = np.concatenate((ans.T, data), axis=1)\n",
    "        \n",
    "        for m in range(epochs):\n",
    "            example = np.random.randint(X.shape[0])\n",
    "            x = [Zita[example]]  \n",
    "            actual_value = target_labels[example]\n",
    "            y = MultiLayerPerceptron(x,actual_value,alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_1( x):  \n",
    "    val = np.concatenate((np.ones(1).T, np.array(x)))\n",
    "    for i in range(0, len(W)):\n",
    "        val = tanh(np.dot(val, W[i]))\n",
    "        val = np.concatenate((np.ones(1).T, np.array(val)))\n",
    "    return val[1]\n",
    "    \n",
    "def predict( X):\n",
    "    value = np.array([]).reshape(0, model[-1])\n",
    "    for p in X:  \n",
    "        y_pred = np.array([[predict_1(p)]]) \n",
    "        value = np.vstack((value,y_pred))\n",
    "    return value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "Network([2,2,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
    "y = np.array([0, 1, 1, 0])\n",
    "\n",
    "learning_rate=0.1  \n",
    "fit(X, y,learning_rate, epochs=6000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final prediction\n",
      "[0 0]   0   [ 0.005625211435814411 ]\n",
      "[0 1]   1   [ 0.9922099656276941 ]\n",
      "[1 0]   1   [ 0.9915443580479176 ]\n",
      "[1 1]   0   [ 0.01694332658239065 ]\n"
     ]
    }
   ],
   "source": [
    "print(\"Final prediction\")\n",
    "l=[]\n",
    "i=0\n",
    "for s in X:\n",
    "    p = predict_1(s)\n",
    "    if p >0.5:\n",
    "        l.append(1)\n",
    "    else:\n",
    "        l.append(0)\n",
    "    print(s,\" \",l[i],\" \",\"[\",p,\"]\")\n",
    "    i=i+1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
